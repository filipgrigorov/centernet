{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_annot(img, annts):\n",
    "    img = io.imread(img['coco_url']) if isinstance(img, dict) else img\n",
    "    if not annts:\n",
    "        raise('Annotation is empty')\n",
    "    for annt in annts:\n",
    "        if 'bbox' in annt:\n",
    "            bbox = np.ascontiguousarray(annt['bbox']).astype(np.int)\n",
    "            img = cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def display_bbox_annot(img, bboxes):\n",
    "    img = io.imread(img['coco_url']) if isinstance(img, dict) else img\n",
    "    for bbox in bboxes:\n",
    "        bbox = bbox.astype(np.int)\n",
    "        img = cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, root, data_type, transforms, in_memory=False, is_debug=False):\n",
    "        self.data_type = data_type\n",
    "        self.transforms = transforms\n",
    "        self.in_memory = in_memory\n",
    "        self.is_debug = is_debug\n",
    "        data_type = data_type.split('/')[-1]\n",
    "        annts_file = f'{ root }/annotations/instances_{ data_type }.json'\n",
    "        self.coco = COCO(annts_file)\n",
    "        \n",
    "        # Note: In theory, ensures persons presence.\n",
    "        category_ids = self.coco.getCatIds(catNms=['person'])\n",
    "        image_ids = self.coco.getImgIds(catIds=category_ids)\n",
    "        self.image_meta = self.coco.loadImgs(image_ids)\n",
    "        \n",
    "        self.images = []; self.annts = []\n",
    "        for image_meta_data in self.image_meta:\n",
    "            annts_ids = self.coco.getAnnIds(imgIds=image_meta_data['id'], catIds=category_ids, iscrowd=False)\n",
    "            img = io.imread(image_meta_data['coco_url']) if self.in_memory else image_meta_data\n",
    "            self.images.append(img)\n",
    "            self.annts.append(self.coco.loadAnns(annts_ids))\n",
    "        \n",
    "        if self.is_debug and len(self.images) > 0 and len(self.annts) > 0:\n",
    "            idx = np.random.randint(0, len(self.images) - 1)\n",
    "            display_image_annot(self.images[idx], self.annts[idx])\n",
    "            \n",
    "        self.n = len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx] if self.in_memory else io.imread(self.images[idx]['coco_url'])\n",
    "        bboxes = [ annt['bbox'] for annt in self.annts[idx] if 'bbox' in annt ]\n",
    "        bboxes = None if len(bboxes) == 0 else np.array(bboxes)\n",
    "        \n",
    "        for bbox in bboxes:\n",
    "            bbox[2] += bbox[0]\n",
    "            bbox[3] += bbox[1]\n",
    "        \n",
    "        if self.is_debug and bboxes.shape[0] > 0:\n",
    "            display_bbox_annot(self.images[idx], bboxes)\n",
    "            \n",
    "        if not self.transforms:\n",
    "            self.transforms = transforms.ToTensor()\n",
    "            \n",
    "        img_tensor = self.transforms(img).float()\n",
    "        bboxes_tensor = torch.from_numpy(bboxes).float() if bboxes.shape[0] > 0 else None\n",
    "        \n",
    "        return (img_tensor, bboxes_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.81s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "root = 'coco'\n",
    "img_paths = 'images'\n",
    "train_dataset = CocoDataset(root, data_type=os.path.join(root, 'train2017'), transforms=None, in_memory=False, is_debug=False)\n",
    "val_dataset = CocoDataset(root, data_type=os.path.join(root, 'val2017'), transforms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable threads: 12\n",
      "cuda version: 11.1\tcudnn version: 8005\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "print(f'Usable threads: { torch.get_num_threads() }')\n",
    "print(f'cuda version: { torch.version.cuda }\\tcudnn version: { cudnn.version() }')\n",
    "\n",
    "num_workers = (0.4 * mp.cpu_count())\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, pin_memory=True, num_workers=num_workers)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, ksize, stride, padding):\n",
    "        super(Conv2d, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_chs, out_chs, ksize, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_chs)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "    \n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_chs):\n",
    "        super(Residual, self).__init__()\n",
    "        \n",
    "        out_chs = in_chs\n",
    "        out1 = out_chs // 4\n",
    "        self.conv1 = Conv2d(in_chs, out1, 1)\n",
    "        out2 = out1 // 4\n",
    "        self.conv2 = Conv2d(out1, out2, 3)\n",
    "        self.conv3 = Conv2d(out2, out_chs, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "# input res: 511 x 511\n",
    "# output res: 128 x 128\n",
    "# Note: The hourglass architecture uses global and local perceptive fields.\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, in_chs):\n",
    "        super(Hourglass, self).__init__()\n",
    "        \n",
    "        # Note: Reduce feature map resolution 5 times\n",
    "        self.enc = nn.Sequential(\n",
    "            self.conv1 = Conv2d(in_chs, 256, 7),\n",
    "            self.conv2 = Residual(256),\n",
    "\n",
    "            self.pool1 = nn.MaxPool2d(2, 2),\n",
    "\n",
    "            self.conv3 = Con2d(256, 512, 7),\n",
    "            self.conv4 = Residual(512),\n",
    "\n",
    "            self.pool2 = nn.MaxPool2d(2, 2),\n",
    "\n",
    "            self.conv5 = Con2d(512, 512, 7),\n",
    "            self.conv6 = Residual(512),\n",
    "\n",
    "            self.pool3 = nn.MaxPool2d(2, 2),\n",
    "\n",
    "            self.conv7 = Con2d(512, 512, 7),\n",
    "            self.conv8 = Residual(512),\n",
    "\n",
    "            self.pool4 = nn.MaxPool2d(2, 2),\n",
    "\n",
    "            self.conv9 = Con2d(512, 512, 7),\n",
    "            self.conv10 = Residual(512),\n",
    "\n",
    "            self.pool5 = nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.dec = nn.Sequential(\n",
    "            self.up5 = nn.Upsample(scaling_factor=2, mode='nearest'),\n",
    "        \n",
    "            self.conv10 = Residual(512),\n",
    "            self.conv9 = Con2d(512, 512, 7),\n",
    "\n",
    "            self.up4 = nn.Upsample(scaling_factor=2, mode='nearest'),\n",
    "\n",
    "            self.conv8 = Residual(512),\n",
    "            self.conv7 = Con2d(512, 512, 7),\n",
    "\n",
    "            self.up3 = nn.Upsample(scaling_factor=2, mode='nearest'),\n",
    "\n",
    "            self.conv6 = Residual(512),\n",
    "            self.conv5 = Con2d(512, 512, 7),\n",
    "\n",
    "            self.up2 = nn.Upsample(scaling_factor=2, mode='nearest'),\n",
    "\n",
    "            self.conv4 = Residual(512),\n",
    "            self.conv3 = Con2d(256, 512, 7),\n",
    "\n",
    "            self.up1 = nn.Upsample(scaling_factor=2, mode='nearest'),\n",
    "\n",
    "            self.conv2 = Residual(256),\n",
    "            self.conv1 = Conv2d(in_chs, 256, 7),\n",
    "        )\n",
    "        \n",
    "        self.skip1 = nn.Sequential(\n",
    "            Residual(256),\n",
    "            Residual(256)\n",
    "        )\n",
    "        \n",
    "        self.skip2 = nn.Sequential(\n",
    "            Residual(512),\n",
    "            Residual(512)\n",
    "        )\n",
    "        \n",
    "        self.skip3 = nn.Sequential(\n",
    "            Residual(512),\n",
    "            Residual(512)\n",
    "        )\n",
    "        \n",
    "        self.skip4 = nn.Sequential(\n",
    "            Residual(512),\n",
    "            Residual(512)\n",
    "        )\n",
    "        \n",
    "        self.skip5 = nn.Sequential(\n",
    "            Residual(512),\n",
    "            Residual(512)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_conns = []\n",
    "        \n",
    "        # Encoding\n",
    "        out = x\n",
    "        for idx in range(len(self.enc)):\n",
    "            out = self.enc[idx]\n",
    "            if idx != 0 and idx % 2 == 0:\n",
    "                skip_conns.append(out)\n",
    "        \n",
    "        # Decoding\n",
    "        for idx in range(len(self.dec)):\n",
    "            out = sel.dec(out)\n",
    "            if idx != 0 and idx % 2 == 0:\n",
    "                \n",
    "            \n",
    "        out5 = self.up5(x)\n",
    "        out = self.conv10(out5)\n",
    "        out = self.conv9(out)\n",
    "        \n",
    "        out4 = self.up4(x)\n",
    "        out = self.conv8(out4)\n",
    "        out = self.conv7(out)\n",
    "        \n",
    "        out3 = self.up3(x)\n",
    "        out = self.conv6(out3)\n",
    "        out = self.conv5(out)\n",
    "        \n",
    "        out2 = self.up2(x)\n",
    "        out = self.conv4(out2)\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        out1 = self.up1(x)\n",
    "        out = self.conv2(out1)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
